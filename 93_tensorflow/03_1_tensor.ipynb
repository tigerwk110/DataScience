{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 引入需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正如名称所示，TensorFlow 这一框架定义和运行涉及张量的计算。张量是对矢量和矩阵向潜在的更高维度的泛化。TensorFlow 在内部将张量表示为基本数据类型的 n 维数组。<br>\n",
    "在编写 TensorFlow 程序时，操作和传递的主要对象是 tf.Tensor。<br>\n",
    "tf.Tensor 对象表示一个部分定义的计算，最终会生成一个值。<br>\n",
    "TensorFlow 程序首先会构建一个 tf.Tensor 对象图，详细说明如何基于其他可用张量计算每个张量，然后运行该图的某些部分以获得期望的结果。\n",
    "\n",
    "tf.Tensor 具有以下属性：\n",
    "- 数据类型（例如 float32、int32 或 string）\n",
    "- 形状\n",
    "张量中的每个元素都具有相同的数据类型，且该数据类型一定是已知的。形状，即张量的维数和每个维度的大小，可能只有部分已知。如果其输入的形状也完全已知，则大多数操作会生成形状完全已知的张量，但在某些情况下，只能在执行图时获得张量的形状。\n",
    "\n",
    "以下是主要张量的类型：\n",
    "\n",
    "- tf.Variable\n",
    "- tf.constant\n",
    "- tf.placeholder\n",
    "- tf.SparseTensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 阶 Rank\n",
    "tf.Tensor 对象的阶是它本身的维数。<br>\n",
    "阶的同义词包括：秩、等级或 n 维。\n",
    "### 0阶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0阶tensor的创建\n",
    "mammal = tf.Variable(\"Elephant\", tf.string)\n",
    "ignition = tf.Variable(451, tf.int16)\n",
    "floating = tf.Variable(3.14159265359, tf.float64)\n",
    "its_complicated = tf.Variable(12.3 - 4.85j, tf.complex64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1阶\n",
    "要创建 1 阶 tf.Tensor 对象，可以传递一个项目列表作为初始值。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr = tf.Variable([\"Hello\"], tf.string)\n",
    "cool_numbers  = tf.Variable([3.14159, 2.71828], tf.float32)\n",
    "first_primes = tf.Variable([2, 3, 5, 7, 11], tf.int32)\n",
    "its_very_complicated = tf.Variable([12.3 - 4.85j, 7.5 - 6.23j], tf.complex64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更高阶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymat = tf.Variable([[7],[11]], tf.int16)\n",
    "myxor = tf.Variable([[False, True],[True, False]], tf.bool)\n",
    "linear_squares = tf.Variable([[4], [9], [16], [25]], tf.int32)\n",
    "squarish_squares = tf.Variable([ [4, 9], [16, 25] ], tf.int32)\n",
    "rank_of_squares = tf.rank(squarish_squares)\n",
    "mymatC = tf.Variable([[7],[11]], tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样，更高阶的张量由一个 n 维数组组成。例如，在图像处理过程中，会使用许多 4 阶张量，维度对应批次大小、图像宽度、图像高度和颜色通道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = tf.zeros([10, 299, 299, 3])  # batch x height x width x color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取tensor的阶\n",
    "要确定 tf.Tensor 对象的阶，需调用 tf.rank 方法。例如，以下方法会程序化地确定上一章节中所定义的 tf.Tensor 的阶："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Rank_5:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tf.rank(my_image)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在我们run之后r会获得my_image的阶，为4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引用 tf.Tensor 切片\n",
    "由于 tf.Tensor 是 n 维单元数组，因此要访问 tf.Tensor 中的某一单元，需要指定 n 个索引。\n",
    "\n",
    "0 阶张量（标量）不需要索引，因为其本身便是单一数字。\n",
    "\n",
    "对于 1 阶张量（矢量），可以通过传递一个索引访问某个数字："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scalar = myxor[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于 2 阶 tf.Tensor，传递两个数字会如预期般返回一个标量：<br>\n",
    "`my_scalar = my_matrix[1, 2]`<br>\n",
    "而传递一个数字则会返回一个矩阵子矢量，如下所示：<br>\n",
    "`my_row_vector = my_matrix[2]<br>\n",
    "my_column_vector = my_matrix[:, 3]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取tensor的形状\n",
    "可以通过两种方法获取 tf.Tensor 的形状。<br>\n",
    "在构建图的时候，询问有关张量形状的已知信息通常很有帮助。可以通过查看 shape 属性（属于 tf.Tensor 对象）获取这些信息。<br>\n",
    "该方法会返回一个 TensorShape 对象，这样可以方便地表示部分指定的形状（因为在构建图的时候，并不是所有形状都完全已知）。\n",
    "\n",
    "也可以获取一个将在运行时表示另一个 tf.Tensor 的完全指定形状的 tf.Tensor。<br>\n",
    "为此，可以调用 tf.shape 操作。如此一来，您可以构建一个图，通过构建其他取决于输入 tf.Tensor 的动态形状的张量来控制张量的形状。\n",
    "\n",
    "例如，以下代码展示了如何创建大小与给定矩阵中的列数相同的零矢量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = tf.zeros(mymat.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改变tensor的形状\n",
    "张量的***元素数量***是其所有形状大小的乘积。<br>\n",
    "标量的元素数量永远是 1。由于通常有许多不同的形状具有相同数量的元素，因此如果能够改变 tf.Tensor 的形状并使其元素固定不变通常会很方便。<br>\n",
    "为此，可以使用 tf.reshape。\n",
    "\n",
    "以下示例演示如何重构张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rank_three_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-b6cc1de077f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mank_three_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_three_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reshape existing content into\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                  \u001b[0;31m# a 6x10 matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmatrixB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#  Reshape existing content into a 3x20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                        \u001b[0;31m# matrix. -1 tells reshape to calculate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rank_three_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "ank_three_tensor = tf.ones([3, 4, 5])\n",
    "matrix = tf.reshape(rank_three_tensor, [6, 10])  # Reshape existing content into\n",
    "                                                 # a 6x10 matrix\n",
    "matrixB = tf.reshape(matrix, [3, -1])  #  Reshape existing content into a 3x20\n",
    "                                       # matrix. -1 tells reshape to calculate\n",
    "                                       # the size of this dimension.\n",
    "matrixAlt = tf.reshape(matrixB, [4, 3, -1])  # Reshape existing content into a\n",
    "                                             #4x3x5 tensor\n",
    "\n",
    "# Note that the number of elements of the reshaped Tensors has to match the\n",
    "# original number of elements. Therefore, the following example generates an\n",
    "# error because no possible value for the last dimension will match the number\n",
    "# of elements.\n",
    "yet_another = tf.reshape(matrixAlt, [13, 2, -1])  # ERROR!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据类型\n",
    "除维度外，张量还具有数据类型。<br>\n",
    "一个 tf.Tensor 只能有一种数据类型。但是，可以将任意数据结构序列化为 string 并将其存储在 tf.Tensor 中。<br>\n",
    "要检查 tf.Tensor 的数据类型，请使用 Tensor.dtype 属性。<br>\n",
    "可以将 tf.Tensor 从一种数据类型转型为另一种（通过 tf.cast）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast a constant integer tensor into floating point.\n",
    "float_tensor = tf.cast(tf.constant([1, 2, 3]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  输出Tensor\n",
    "出于调试目的，您可能需要输出 tf.Tensor 的值。虽然 tfdbg 提供高级调试支持，但 TensorFlow 也有一个操作可以直接输出 tf.Tensor 的值。\n",
    "请注意，输出 tf.Tensor 时很少使用以下模式：\n",
    "`t = <<some tensorflow operation>>`<br>\n",
    "`print(t)  # This will print the symbolic tensor when the graph is being built.`<br>\n",
    "`          # This tensor does not have a value in this context.`<br>\n",
    "上述代码会输出 tf.Tensor 对象（表示延迟计算），而不是其值。TensorFlow 提供了 tf.Print 操作，该操作会返回其第一个张量参数（保持不变），同时输出作为第二个参数传递的 tf.Tensor 集合。\n",
    "\n",
    "要正确使用 tf.Print，必须使用其返回的值。请参阅下文的示例：\n",
    "\n",
    "`t = <<some tensorflow operation>>`<br>\n",
    "`tf.Print(t, [t])  # This does nothing`<br>\n",
    "`t = tf.Print(t, [t])  # Here we are using the value returned by tf.Print`<br>\n",
    "`result = t + 1  # Now when result is evaluated the value of `t` will be printed.`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
