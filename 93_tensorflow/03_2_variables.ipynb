{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 引入需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "graph_tensor = tf.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow 变量是表示程序处理的共享持久状态的最佳方法。\n",
    "\n",
    "我们使用 tf.Variable 类操作变量。tf.Variable 表示可通过对其运行操作来改变其值的张量。与 tf.Tensor 对象不同，tf.Variable 存在于单个 session.run 调用的上下文之外。\n",
    "\n",
    "在 TensorFlow 内部，tf.Variable 会存储持久性张量。具体 op 允许您读取和修改此张量的值。这些修改在多个 tf.Session 之间是可见的，因此对于一个 tf.Variable，多个工作器可以看到相同的值。\n",
    "\n",
    "## 创建变量\n",
    "创建变量的最佳方式是调用 tf.get_variable 函数。此函数要求您指定变量的名称。其他副本将使用此名称访问同一变量，以及在对模型设置检查点和导出模型时指定此变量的值。tf.get_variable 还允许您重复使用先前创建的同名变量，从而轻松定义重复利用层的模型。\n",
    "\n",
    "要使用 tf.get_variable 创建变量，只需提供名称和形状即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "my_variable = tf.get_variable(\"my_variable\", [1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这将创建一个名为“my_variable”的变量，该变量是形状为 [1, 2, 3] 的三维张量。默认情况下，此变量将具有 dtypetf.float32，其初始值将通过 tf.glorot_uniform_initializer 随机设置。\n",
    "\n",
    "您可以选择为 tf.get_variable 指定 dtype 和初始化器。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_int_variable = tf.get_variable(\"my_int_variable\", [1, 2, 3], dtype=tf.int32,\n",
    "  initializer=tf.zeros_initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow 提供了许多方便的初始化器。或者，您也可以将 tf.Variable 初始化为 tf.Tensor 的值。例如：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_variable = tf.get_variable(\"other_variable\", dtype=tf.int32,\n",
    "  initializer=tf.constant([23, 42]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，当初始化器是 tf.Tensor 时，您不应指定变量的形状，因为将使用初始化器张量的形状。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化变量\n",
    "变量必须先初始化后才可使用。如果您在低级别 TensorFlow API 中进行编程（即您在显式创建自己的图和会话），则必须明确初始化变量。tf.contrib.slim、tf.estimator.Estimator 和 Keras 等大多数高级框架在训练模型前会自动为您初始化变量。\n",
    "\n",
    "显式初始化在其他方面很有用。它允许您在从检查点重新加载模型时不用重新运行潜在资源消耗大的初始化器，并允许在分布式设置中共享随机初始化的变量时具有确定性。\n",
    "\n",
    "要在训练开始前一次性初始化所有可训练变量，请调用 tf.global_variables_initializer()。此函数会返回一个操作，负责初始化 tf.GraphKeys.GLOBAL_VARIABLES 集合中的所有变量。运行此操作会初始化所有变量。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "# Now all variables are initialized.\n",
    "# 如果确实需要自行初始化变量，则可以运行变量的初始化器操作。例如：\n",
    "session.run(my_variable.initializer)\n",
    "# 可以查询哪些变量尚未初始化。例如，以下代码会打印所有尚未初始化的变量名称：\n",
    "print(session.run(tf.report_uninitialized_variables()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，默认情况下，tf.global_variables_initializer 不会指定变量的初始化顺序。因此，如果变量的初始值取决于另一变量的值，那么很有可能会出现错误。任何时候，如果您在并非所有变量都已初始化的上下文中使用某个变量值（例如在初始化某个变量时使用另一变量的值），最好使用 variable.initialized_value()，而非 variable："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph_tensor.as_default():\n",
    "    v = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\n",
    "    w = tf.get_variable(\"w\", initializer=v.initialized_value() + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用变量\n",
    "要在 TensorFlow 图中使用 tf.Variable 的值，只需将其视为普通 tf.Tensor 即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph_tensor) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    w = v + 1  # w is a tf.Tensor which is computed based on the value of v.\n",
    "           # Any time a variable is used in an expression it gets automatically\n",
    "           # converted to a tf.Tensor representing its value.\n",
    "    print(sess.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要为变量赋值，使用 assign、assign_add 方法。例如，以下就是调用这些方法的方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nvar is used exception.\\nIf you want to execute the block of the graph creation again, TensorFlow will raise this error, because the graph (with it's layer names) already exists. If you run this notebook block after block there should be absolutely no problem.\\nIn the case you want to re-run codeblock 3 (for what ever reason) just insert a simple tf.reset_default_graph() at the beginning of the block. This will reset the graph you have already create and though you can create it again.\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session(graph=graph_tensor) as sess:\n",
    "    #v = tf.get_variable(\"var\", shape=(), initializer=tf.zeros_initializer())\n",
    "    assignment = v.assign_add(1)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(assignment))  # or assignment.op.run(), or assignment.eval()\n",
    "\n",
    "'''\n",
    "var is used exception.\n",
    "If you want to execute the block of the graph creation again, TensorFlow will raise this error, because the graph (with it's layer names) already exists. If you run this notebook block after block there should be absolutely no problem.\n",
    "In the case you want to re-run codeblock 3 (for what ever reason) just insert a simple tf.reset_default_graph() at the beginning of the block. This will reset the graph you have already create and though you can create it again.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共享变量\n",
    "TensorFlow 支持两种共享变量的方式：\n",
    "\n",
    "- 显式传递 tf.Variable 对象。\n",
    "- 将 tf.Variable 对象隐式封装在 tf.variable_scope 对象内。\n",
    "虽然显式传递变量的代码非常清晰，但有时编写在其实现中隐式使用变量的 TensorFlow 函数非常方便。tf.layers 中的大多数功能层以及所有 tf.metrics 和部分其他库实用程序都使用这种方法。\n",
    "\n",
    "变量作用域允许您在调用隐式创建和使用变量的函数时控制变量重用。作用域还允许您以分层和可理解的方式命名变量。\n",
    "\n",
    "例如，假设我们编写一个函数来创建一个卷积/relu 层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_relu(input, kernel_shape, bias_shape):\n",
    "    # Create variable named \"weights\".\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape,\n",
    "        initializer=tf.random_normal_initializer())\n",
    "    # Create variable named \"biases\".\n",
    "    biases = tf.get_variable(\"biases\", bias_shape,\n",
    "        initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input, weights,\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "此函数使用短名称 weights 和 biases，这有利于清晰区分二者。然而，在真实模型中，我们需要很多此类卷积层，而且重复调用此函数将不起作用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = tf.random_normal([1,10,10,32])\n",
    "input2 = tf.random_normal([1,20,20,32])\n",
    "x = conv_relu(input1, kernel_shape=[5, 5, 32, 32], bias_shape=[32])\n",
    "x = conv_relu(x, kernel_shape=[5, 5, 32, 32], bias_shape = [32])  # This fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "由于期望的操作不清楚（创建新变量还是重新使用现有变量？），因此 TensorFlow 将会失败。不过，在不同作用域内调用 conv_relu 可表明我们想要创建新变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_image_filter(input_images):\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "        relu1 = conv_relu(input_images, [5, 5, 32, 32], [32])\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        # Variables created here will be named \"conv2/weights\", \"conv2/biases\".\n",
    "        return conv_relu(relu1, [5, 5, 32, 32], [32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "如果您想要共享变量，有两种方法可供选择。首先，您可以使用 reuse=True 创建具有相同名称的作用域："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"model\"):\n",
    "  output1 = my_image_filter(input1)\n",
    "with tf.variable_scope(\"model\", reuse=True):\n",
    "  output2 = my_image_filter(input2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "您也可以调用 scope.reuse_variables() 以触发重用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"model\") as scope:\n",
    "  output1 = my_image_filter(input1)\n",
    "  scope.reuse_variables()\n",
    "  output2 = my_image_filter(input2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
