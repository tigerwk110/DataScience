{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用低级别 TensorFlow API (TensorFlow Core) 开始编程\n",
    "\n",
    "## 目录\n",
    "- 使用 tf.Graph 和 tf.Session 管理 TensorFlow 程序\n",
    "\n",
    "- 使用 tf.Session 运行 TensorFlow 操作。\n",
    "- 在此低级别环境中使用高级别组件（数据集、层和 feature_columns）。\n",
    "- 构建自己的训练循环，而不是使用 Estimator 提供的训练循环。<br>\n",
    "\n",
    "最好还是尽可能使用更高阶的 API 构建模型。\n",
    "以下是 TensorFlow 低级API 为何很重要的原因：\n",
    "\n",
    "- 如果您能够直接使用低阶 TensorFlow 操作，实验和调试都会更直接。\n",
    "- 在使用更高阶的 API 时，能够理解其内部工作原理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 引入需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Values （张量）\n",
    "TensorFlow 中的核心数据单位是张量(**tensor**)。一个张量由一组形成阵列（**任意维数**）的原始值组成。张量的阶(**rank**)是它的维数，而它的形状(**shape**)是一个整数元组，指定了阵列每个维度的长度。<br>\n",
    "TensorFlow 使用 numpy 阵列来表示张量值。<br>\n",
    "\n",
    "以下是张量值的一些示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1.0, 2.0, 3.0]], [[7.0, 8.0, 9.0]]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一个阶为0的tensor, shape是[]的标量\n",
    "3. \n",
    "# 一个阶为1的tensor, shape是[3]的向量\n",
    "[1., 2., 3.] \n",
    "# 一个阶为2的tensor, shape是[2， 3]的矩阵\n",
    "[[1., 2., 3.], [4., 5., 6.]] \n",
    "# 一个阶为3的tensor, shape是[2, 1, 3]的矩阵\n",
    "[[[1., 2., 3.]], [[7., 8., 9.]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***请前往03_1_tensor, 03_2_variable***, 获得详细的tensor介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Core\n",
    "可以将 TensorFlow Core 程序看作由两个互相独立的部分组成：\n",
    "\n",
    "- 构建计算图 (tf.Graph)。\n",
    "- 运行计算图（使用 tf.Session）。\n",
    "\n",
    "### 计算图\n",
    "***一般而言，使用TensorFlow程序的流程是先创建一个图，然后在session中启动它。***\n",
    "\n",
    "计算图是排列成一个图的一系列 TensorFlow 指令。图由两种类型的对象组成。\n",
    "\n",
    "- 操作（简称“op”）：图的节点。操作描述了消耗和生成张量的计算。\n",
    "- 张量：图的边。它们代表将流经图的值。大多数 TensorFlow 函数会返回 tf.Tensors。\n",
    "我们来构建一个简单的计算图。<br>\n",
    "最基本的指令是一个常量。构建指令的 Python 函数将一个张量值作为输入值。<br>\n",
    "生成的指令不需要输入值。它在运行时输出的是被传递给构造函数的值。<br>\n",
    "我们可以创建如下所示的两个浮点数常量 a 和 b："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_10:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_11:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add_8:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(3.0, dtype=tf.float32)\n",
    "b = tf.constant(4.0) # also tf.float32 implicitly\n",
    "total = a + b\n",
    "print(a)\n",
    "print(b)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意**，打印张量并不会如预期的那样输出值 3.0、4.0 和 7.0。<br>\n",
    "上述语句只会构建计算图。这些 tf.Tensor 对象仅代表将要运行的操作的结果。\n",
    "\n",
    "图中的每个指令都拥有唯一的名称。这个名称不同于使用 Python 分配给相应对象的名称。张量是根据生成它们的指令命名的，后面跟着输出索引，如 \"add:0\"。\n",
    "\n",
    "## 会话 (Session)\n",
    "要评估张量，需要实例化一个 tf.Session 对象）。会话会封装 TensorFlow 运行时的状态，并运行 TensorFlow 操作。<br>\n",
    "如果说 tf.Graph 像一个 .py 文件，那么 tf.Session 就像一个 python 可执行对象。\n",
    "\n",
    "下面的代码会创建一个 tf.Session 对象，然后调用其 run 方法来评估我们在上文中创建的 total 张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当使用 Session.run 请求输出节点时，TensorFlow 会回溯整个图，<br>\n",
    "并流经提供了所请求的输出节点对应的输入值的所有节点。因此此指令会打印预期的值 7.0：<br>\n",
    "可以将多个张量传递给 tf.Session.run。run 方法以透明方式处理元组或字典的任何组合，如下例所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ab': (3.0, 4.0), 'total': 7.0}\n"
     ]
    }
   ],
   "source": [
    "print(sess.run({'ab':(a, b), 'total':total}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在调用 tf.Session.run 期间，任何 tf.Tensor 都只有单个值。<br>\n",
    "例如，以下代码调用 tf.random_uniform 来生成一个 tf.Tensor，后者会生成随机的三元素矢量（值位于 [0,1) 区间内）。<br>\n",
    "每次调用 run 时，结果都会显示不同的随机值，但在单个 run 期间（out1 和 out2 接收到相同的随机输入值），结果显示的值是一致的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98193777 0.8016151  0.04787409]\n",
      "[0.67761266 0.88284373 0.74878335]\n",
      "(array([1.588478 , 1.4116062, 1.8086885], dtype=float32), array([2.588478 , 2.4116063, 2.8086886], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "vec = tf.random_uniform(shape=(3,))\n",
    "out1 = vec + 1\n",
    "out2 = vec + 2\n",
    "print(sess.run(vec))\n",
    "print(sess.run(vec))\n",
    "print(sess.run((out1, out2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feeding\n",
    "目前的图只能使用常量值，因此它总是生成一个常量结果。<br>\n",
    "图可以参数化以便接受外部输入，也称为占位符。占位符表示在稍后提供值，它就像函数参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面三行有点像函数。我们定义了这个函数的两个输入参数（x 和 y），然后对它们指令。<br>\n",
    "我们可以使用 run 方法的 feed_dict 参数为占位符提供具体的值，从而评估这个具有多个输入的图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(z, feed_dict={x: 3, y: 4.5}))\n",
    "print(sess.run(z, feed_dict={x: [1, 3], y: [2, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 层 （Layer）\n",
    "可训练的模型必须修改图中的值，以便在输入相同值的情况下获得新的输出值。将可训练参数添加到图中的首选方法是层。<br>\n",
    "\n",
    "层将变量和作用于它们的操作打包在一起。例如，全连接层会对每个输出对应的所有输入执行加权和，并应用激活函数（可选）。连接权重和偏差由层对象管理。\n",
    "### 创建层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "linear_model = tf.layers.Dense(units=1)\n",
    "y = linear_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "层会检查其输入数据，以确定其内部变量的大小。因此，我们必须在这里设置 x 占位符的形状，以便层构建正确大小的权重矩阵。\n",
    "\n",
    "我们现在已经定义了输出值 y 的计算，在我们运行计算之前，还需要处理一个细节。\n",
    "### 初始化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "global_variables_initializer 仅会初始化创建初始化程序时图中就存在的变量。因此应该在构建图表的最后一步添加初始化程序。\n",
    "### 执行层\n",
    "我们现在已经完成了层的初始化，可以像处理任何其他张量一样评估 linear_model 的输出张量了。例如，下面的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.778865]\n",
      " [10.312775]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(y, {x: [[1, 2, 3],[4, 5, 6]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "已经了解 TensorFlow 核心部分的基础知识了，我们来手动训练一个小型回归模型吧。\n",
    "### 定义数据\n",
    "我们首先来定义一些输入值 `x`，以及每个输入值的预期输出值 `y_true`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[1], [2], [3], [4]], dtype=tf.float32)\n",
    "y_true = tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型\n",
    "接下来，建立一个简单的线性模型，其输出值只有 1 个："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5243298]\n",
      " [1.0486596]\n",
      " [1.5729893]\n",
      " [2.0973191]]\n"
     ]
    }
   ],
   "source": [
    "linear_model = tf.layers.Dense(units=1)\n",
    "\n",
    "# 进行预测、还没有训练，所以效果不是很好\n",
    "y_pred = linear_model(x)\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失\n",
    "要优化模型，首先需要定义损失。我们将使用均方误差，这是回归问题的标准损失。\n",
    "\n",
    "虽然可以使用较低级别的数学运算手动定义，但 tf.losses 模块提供了一系列常用的损失函数。可以使用它来计算均方误差，具体操作如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.805211\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.mean_squared_error(labels=y_true, predictions=y_pred)\n",
    "\n",
    "print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练\n",
    "TensorFlow 提供了执行标准优化算法的优化器。这些优化器被实现为 tf.train.Optimizer 的子类。它们会逐渐改变每个变量，以便将损失最小化。最简单的优化算法是梯度下降法，由 tf.train.GradientDescentOptimizer 实现。它会根据损失相对于变量的导数大小来修改各个变量。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该代码构建了优化所需的所有图组件，并返回一个训练指令。该训练指令在运行时会更新图中的变量。您可以按以下方式运行该指令："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.805211\n",
      "7.590361\n",
      "5.35909\n",
      "3.8103056\n",
      "2.7350888\n",
      "1.9884733\n",
      "1.4698704\n",
      "1.1094842\n",
      "0.85888433\n",
      "0.684466\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  _, loss_value = sess.run((train, loss))\n",
    "  print(loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实践\n",
    "请将上面的程序写成一个完整的程序"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
