{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Programing \n",
    "Keras 是一个用于构建和训练深度学习模型的高阶API。它可用于快速设计原型、高级研究和生产，具有以下三个主要优势：\n",
    "\n",
    "- 方便用户使用\n",
    "Keras 具有针对常见用例做出优化的简单而一致的界面。它可针对用户错误提供切实可行的清晰反馈。\n",
    "- 模块化和可组合\n",
    "将可配置的构造块连接在一起就可以构建 Keras 模型，并且几乎不受限制。\n",
    "- 易于扩展\n",
    "可以编写自定义构造块以表达新的研究创意，并且可以创建新层、损失函数并开发先进的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入keras \n",
    "`tf.keras` 是 TensorFlow 对 Keras API 规范的实现。\n",
    "\n",
    "是一个用于构建和训练模型的高阶 API，包含对 TensorFlow 特定功能（例如 Eager Execution、tf.data 管道和 Estimator）的支持。\n",
    "\n",
    "tf.keras 使 TensorFlow 更易于使用，并且不会牺牲灵活性和性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras` 可以运行任何与 Keras 兼容的代码，但请注意：\n",
    "\n",
    "保存模型的权重时，tf.keras 默认采用检查点格式。请传递 save_format='h5' 以使用 HDF5。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建简单的模型\n",
    "### 序列模型\n",
    "在 Keras 中，可以通过组合层来构建模型。模型（通常）是由层构成的图。\n",
    "\n",
    "最常见的模型类型是层的堆叠：`tf.keras.Sequential` 模型。\n",
    "\n",
    "要构建一个简单的全连接网络（即多层感知器），请运行以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置层\n",
    "我们可以使用很多 `tf.keras.layers`，它们具有一些相同的构造函数参数：\n",
    "\n",
    "- activation：\n",
    "设置层的激活函数。此参数由内置函数的名称指定，或指定为可调用对象。默认情况下，系统不会应用任何激活函数。\n",
    "- kernel_initializer 和 bias_initializer：\n",
    "创建层权重（核和偏差）的初始化方案。此参数是一个名称或可调用对象，默认为 \"Glorot uniform\" 初始化器。\n",
    "- kernel_regularizer 和 bias_regularizer：\n",
    "应用层权重（核和偏差）的正则化方案，例如 L1 或 L2 正则化。默认情况下，系统不会应用正则化函数。\n",
    "以下代码使用构造函数参数实例化 `tf.keras.layers.Dense` 层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f70539f0e10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sigmoid layer:\n",
    "layers.Dense(64, activation='sigmoid')\n",
    "# Or:\n",
    "layers.Dense(64, activation=tf.sigmoid)\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "layers.Dense(64, kernel_initializer='orthogonal')\n",
    "\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "layers.Dense(64, bias_initializer=tf.keras.initializers.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练和评估\n",
    "### 设置训练流程\n",
    "构建好模型后，通过调用 compile 方法配置该模型的学习流程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "layers.Dense(64, activation='relu'),\n",
    "# Add another:\n",
    "layers.Dense(64, activation='relu'),\n",
    "# Add a softmax layer with 10 output units:\n",
    "layers.Dense(10, activation='softmax')]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras.Model.compile` 采用三个重要参数：\n",
    "\n",
    "- optimizer：\n",
    "此对象会指定训练过程。从 tf.train 模块向其传递优化器实例，例如 tf.train.AdamOptimizer、tf.train.RMSPropOptimizer 或 tf.train.GradientDescentOptimizer。\n",
    "- loss：要\n",
    "在优化期间最小化的函数。常见选择包括均方误差 (mse)、categorical_crossentropy 和 binary_crossentropy。损失函数由名称或通过从 tf.keras.losses 模块传递可调用对象来指定。\n",
    "- metrics：\n",
    "用于监控训练。它们是 tf.keras.metrics 模块中的字符串名称或可调用对象。\n",
    "以下代码展示了配置模型以进行训练的几个示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Configure a model for mean-squared error regression.\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "              loss='mse',       # mean squared error\n",
    "              metrics=['mae'])  # mean absolute error\n",
    "\n",
    "# Configure a model for categorical classification.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入 NumPy 数据\n",
    "对于小型数据集，请使用内存中的 NumPy 数组训练和评估模型。使用 fit 方法使模型与训练数据“拟合”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 472us/sample - loss: 11.5007 - categorical_accuracy: 0.1030\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 11.4544 - categorical_accuracy: 0.1050\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 11.4480 - categorical_accuracy: 0.1110\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 11.4377 - categorical_accuracy: 0.1220\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 11.4347 - categorical_accuracy: 0.1050\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 11.4348 - categorical_accuracy: 0.1130\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 11.4334 - categorical_accuracy: 0.0920\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 11.4315 - categorical_accuracy: 0.1160\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 11.4276 - categorical_accuracy: 0.1160\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 11.4218 - categorical_accuracy: 0.1020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f70534a76a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.Model.fit 采用三个重要参数：\n",
    "\n",
    "- epochs：\n",
    "以周期为单位进行训练。一个周期是对整个输入数据的一次迭代（以较小的批次完成迭代）。\n",
    "- batch_size：\n",
    "当传递 NumPy 数据时，模型将数据分成较小的批次，并在训练期间迭代这些批次。此整数指定每个批次的大小。请注意，如果样本总数不能被批次大小整除，则最后一个批次可能更小。\n",
    "- validation_data：\n",
    "在对模型进行原型设计时，需要轻松监控该模型在某些验证数据上达到的效果。传递此参数（输入和标签元组）可以让该模型在每个周期结束时以推理模式显示所传递数据的损失和指标。\n",
    "\n",
    "下面是使用 validation_data 的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 174us/sample - loss: 11.4395 - categorical_accuracy: 0.0920 - val_loss: 11.3985 - val_categorical_accuracy: 0.0800\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 11.4360 - categorical_accuracy: 0.1010 - val_loss: 11.3999 - val_categorical_accuracy: 0.0900\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 78us/sample - loss: 11.4351 - categorical_accuracy: 0.1050 - val_loss: 11.4031 - val_categorical_accuracy: 0.1400\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 75us/sample - loss: 11.4333 - categorical_accuracy: 0.1070 - val_loss: 11.4212 - val_categorical_accuracy: 0.0900\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 78us/sample - loss: 11.4354 - categorical_accuracy: 0.0990 - val_loss: 11.3960 - val_categorical_accuracy: 0.0400\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 77us/sample - loss: 11.4319 - categorical_accuracy: 0.1250 - val_loss: 11.4071 - val_categorical_accuracy: 0.1300\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 75us/sample - loss: 11.4311 - categorical_accuracy: 0.1210 - val_loss: 11.4044 - val_categorical_accuracy: 0.1300\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 75us/sample - loss: 11.4286 - categorical_accuracy: 0.1130 - val_loss: 11.4158 - val_categorical_accuracy: 0.1200\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 11.4286 - categorical_accuracy: 0.1010 - val_loss: 11.4054 - val_categorical_accuracy: 0.0800\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 76us/sample - loss: 11.4238 - categorical_accuracy: 0.1180 - val_loss: 11.4397 - val_categorical_accuracy: 0.1500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f70500ac358>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入 tf.data 数据集\n",
    "使用 Datasets API 可扩展为大型数据集或多设备训练。将 tf.data.Dataset 实例传递到 fit 方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 11.4100 - categorical_accuracy: 0.1125\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4028 - categorical_accuracy: 0.1261\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4257 - categorical_accuracy: 0.1368\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.3786 - categorical_accuracy: 0.1464\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4298 - categorical_accuracy: 0.1560\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4009 - categorical_accuracy: 0.1688\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.3969 - categorical_accuracy: 0.1517\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.3863 - categorical_accuracy: 0.1506\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.3733 - categorical_accuracy: 0.1656\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.3498 - categorical_accuracy: 0.1720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f70500acb00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiates a toy dataset instance:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上方代码中，fit 方法使用了 steps_per_epoch 参数（表示模型在进入下一个周期之前运行的训练步数）。由于 Dataset 会生成批次数据，因此该代码段不需要 batch_size。\n",
    "\n",
    "数据集也可用于验证："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估和预测\n",
    "tf.keras.Model.evaluate 和 tf.keras.Model.predict 方法可以使用 NumPy 数据和 tf.data.Dataset。\n",
    "\n",
    "要评估所提供数据的推理模式损失和指标，请运行以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 137us/sample - loss: 11.5580 - categorical_accuracy: 0.1070\n",
      "[11.55795327758789, 0.107]\n",
      "[[0.10135583 0.10042981 0.09321083 ... 0.10499071 0.09247445 0.09271517]\n",
      " [0.11304542 0.0936415  0.09559053 ... 0.09806406 0.09711497 0.11101819]\n",
      " [0.08773647 0.09440125 0.08379943 ... 0.09716568 0.09980063 0.08566275]\n",
      " ...\n",
      " [0.09844451 0.10513283 0.09359249 ... 0.10395192 0.09812948 0.08804629]\n",
      " [0.09220661 0.10661891 0.0846066  ... 0.11001663 0.09786028 0.07405312]\n",
      " [0.08121546 0.10571145 0.07830639 ... 0.09388811 0.11345306 0.08550307]]\n"
     ]
    }
   ],
   "source": [
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "print(model.evaluate(data, labels))\n",
    "\n",
    "print(model.predict(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建高级模型\n",
    "### 函数式 API\n",
    "tf.keras.Sequential 模型是层的简单堆叠，无法表示任意模型。使用 Keras 函数式 API 可以构建复杂的模型拓扑，例如：\n",
    "\n",
    "- 多输入模型\n",
    "- 多输出模型\n",
    "- 具有共享层的模型（同一层被调用多次），\n",
    "\n",
    "使用函数式 API 构建的模型具有以下特征：\n",
    "\n",
    "- 层实例可调用并返回张量。\n",
    "- 输入张量和输出张量用于定义 tf.keras.Model 实例。\n",
    "- 此模型的训练方式和 Sequential 模型一样。\n",
    "以下示例使用函数式 API 构建一个简单的全连接网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(32,))  # Returns a placeholder tensor\n",
    "\n",
    "# A layer instance is callable on a tensor, and returns a tensor.\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在给定输入和输出的情况下实例化模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 329us/sample - loss: 11.5609 - acc: 0.1060\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 75us/sample - loss: 11.5345 - acc: 0.0990\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 11.5203 - acc: 0.1020\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 11.5114 - acc: 0.1030\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 11.5033 - acc: 0.1050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7030167be0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs\n",
    "model.fit(data, labels, batch_size=32, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存和恢复\n",
    "\n",
    "模型可以保存到一个文件中，其中包含权重值、模型配置乃至优化器配置。这样，您就可以对模型设置检查点并稍后从完全相同的状态继续训练，而无需访问原始代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 397us/sample - loss: 11.5194 - acc: 0.1000\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 11.5065 - acc: 0.1060\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 11.5035 - acc: 0.1010\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 11.5027 - acc: 0.1160\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 11.5023 - acc: 0.1150\n"
     ]
    }
   ],
   "source": [
    "# Create a trivial model\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Dense(10, activation='softmax', input_shape=(32,)),\n",
    "  layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data, labels, batch_size=32, epochs=5)\n",
    "\n",
    "# Save entire model to a HDF5 file\n",
    "model.save('my_model.h5')\n",
    "\n",
    "# Recreate the exact same model, including weights and optimizer.\n",
    "model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实践\n",
    "## 构建一个完整的具有训练与评估的项目\n",
    "框架：Tensorflow的Keras API\n",
    "数据集：Cifar10\n",
    "要求：\n",
    "1. 使用Keras 的Sequential搭建一个Alexnet网络\n",
    "2. 需要有训练与评估脚本\n",
    "3. 使用tensorboard可视化训练过程（可视化loss）\n",
    "4. 每一个epoch都保存一次模型\n",
    "5. 对指定模型进行评估\n",
    "6. 编码符合PEP8编码规范\n",
    "7. 使用SGD优化器，学习率为0.001，momentum为0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提示1: Alexnet定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer 1\n",
    "model.add(layers.Conv2D(48, kernel_size=(3,3),strides=(1,1), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "#Layer 2\n",
    "model.add(layers.Conv2D(128, kernel_size=(3,3), activation='relu', padding='same') )\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "#Layer 3\n",
    "model.add(layers.Conv2D(192, kernel_size=(3,3), activation='relu', padding='same') )\n",
    "\n",
    "#Layer 4\n",
    "model.add(layers.Conv2D(192, kernel_size=(3,3), activation='relu', padding='same') )\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "#Layer 5\n",
    "model.add(layers.Conv2D(128, kernel_size=(3,3), activation='relu', padding='same') )\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "#Layer 6\n",
    "model.add(layers.Dense(4096))\n",
    "\n",
    "#Layer 7\n",
    "model.add(layers.Dense(4096))\n",
    "\n",
    "#Prediction\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 提示2: lable需要one-hot编码\n",
    "#### 提示3: loss使用categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
