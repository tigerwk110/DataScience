{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取输入数据\n",
    "## 消费 NumPy 数组\n",
    "如果所有输入数据都适合存储在内存中，则根据输入数据创建 Dataset 的最简单方法是使用`Dataset.from_tensor_slices()`\n",
    "将它们转换为 tf.Tensor 对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.28547566, 0.22282825]), array([0.07755469]))\n",
      "(array([0.61760959, 0.0492551 ]), array([0.91944163]))\n",
      "(array([0.19500593, 0.79088898]), array([0.8959786]))\n",
      "(array([0.19422631, 0.32383958]), array([0.0190849]))\n",
      "(array([0.64358333, 0.9216484 ]), array([0.7334814]))\n",
      "(array([0.01495688, 0.35054628]), array([0.45931417]))\n",
      "(array([0.18024108, 0.72396095]), array([0.13781602]))\n",
      "(array([0.06179509, 0.7726721 ]), array([0.58175556]))\n",
      "(array([0.1859441 , 0.25900502]), array([0.05224747]))\n",
      "(array([0.39245439, 0.1266883 ]), array([0.74371682]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sess=tf.InteractiveSession()\n",
    "\n",
    "features, labels = (np.random.sample((100,2)), np.random.sample((100,1)))\n",
    "\n",
    "# Assume that each row of `features` corresponds to the same row as `labels`.\n",
    "assert features.shape[0] == labels.shape[0]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "# make_one_shot_iterator 一次访问Dataset中的一个元素\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "for i in range(10):\n",
    "    value = sess.run(next_element)\n",
    "    print(value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，上面的代码段会将 features 和 labels 数组作为 tf.constant() 指令嵌入在 TensorFlow 图中。这样非常适合小型数据集，但会浪费内存，因为会多次复制数组的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.62839225, 0.0977435 ]), array([0.17247136]))\n",
      "(array([0.09415541, 0.96974174]), array([0.42514313]))\n",
      "(array([0.06437329, 0.40008927]), array([0.77355629]))\n",
      "(array([0.65468868, 0.9642231 ]), array([0.0815337]))\n",
      "(array([0.13263284, 0.02321559]), array([0.57445881]))\n",
      "(array([0.20099834, 0.00196639]), array([0.41225941]))\n",
      "(array([0.85103846, 0.80587609]), array([0.42399514]))\n",
      "(array([0.00628278, 0.13168694]), array([0.44083654]))\n",
      "(array([0.17048121, 0.06848028]), array([0.7710174]))\n",
      "(array([0.27084372, 0.96403615]), array([0.40035554]))\n"
     ]
    }
   ],
   "source": [
    "features, labels = (np.random.sample((100,2)), np.random.sample((100,1)))\n",
    "\n",
    "features_placeholder = tf.placeholder(features.dtype, features.shape)\n",
    "labels_placeholder = tf.placeholder(labels.dtype, labels.shape)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "sess.run(iterator.initializer, feed_dict={features_placeholder: features,\n",
    "                                          labels_placeholder: labels})\n",
    "for i in range(10):\n",
    "    value = sess.run(next_element)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 消费TFRecord数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实就是通过tf.data.TFRecordDataset这个api来读取到TFRecord文件，生成处dataset对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(string_record):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(string_record)\n",
    "    \n",
    "    height = int(example.features.feature['height'].int64_list.value[0])\n",
    "    width = int(example.features.feature['width'].int64_list.value[0])\n",
    "    img_string = (example.features.feature['image_raw'].bytes_list.value[0])\n",
    "    label = int(example.features.feature['label'].int64_list.value[0])\n",
    "    \n",
    "    img_1d = np.frombuffer(img_string, dtype=np.uint8)\n",
    "    img = img_1d.reshape((height, width, -1))\n",
    "\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[ 59,  62,  63],\n",
      "        [ 43,  46,  45],\n",
      "        [ 50,  48,  43],\n",
      "        ...,\n",
      "        [158, 132, 108],\n",
      "        [152, 125, 102],\n",
      "        [148, 124, 103]],\n",
      "\n",
      "       [[ 16,  20,  20],\n",
      "        [  0,   0,   0],\n",
      "        [ 18,   8,   0],\n",
      "        ...,\n",
      "        [123,  88,  55],\n",
      "        [119,  83,  50],\n",
      "        [122,  87,  57]],\n",
      "\n",
      "       [[ 25,  24,  21],\n",
      "        [ 16,   7,   0],\n",
      "        [ 49,  27,   8],\n",
      "        ...,\n",
      "        [118,  84,  50],\n",
      "        [120,  84,  50],\n",
      "        [109,  73,  42]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[208, 170,  96],\n",
      "        [201, 153,  34],\n",
      "        [198, 161,  26],\n",
      "        ...,\n",
      "        [160, 133,  70],\n",
      "        [ 56,  31,   7],\n",
      "        [ 53,  34,  20]],\n",
      "\n",
      "       [[180, 139,  96],\n",
      "        [173, 123,  42],\n",
      "        [186, 144,  30],\n",
      "        ...,\n",
      "        [184, 148,  94],\n",
      "        [ 97,  62,  34],\n",
      "        [ 83,  53,  34]],\n",
      "\n",
      "       [[177, 144, 116],\n",
      "        [168, 129,  94],\n",
      "        [179, 142,  87],\n",
      "        ...,\n",
      "        [216, 184, 140],\n",
      "        [151, 118,  84],\n",
      "        [123,  92,  72]]], dtype=uint8), 6)\n"
     ]
    }
   ],
   "source": [
    "# 定义dataset 和 一些列trasformation method\n",
    "dataset = tf.data.TFRecordDataset('./keras_cifar10_tfreocrds/cifar10_train.tfrceords')\n",
    "\n",
    "# 创建Iterator\n",
    "sample_iter = dataset.make_one_shot_iterator()\n",
    "# 获取next_sample\n",
    "next_element = sample_iter.get_next()\n",
    "\n",
    "for i in range(1):\n",
    "    value = sess.run(next_element)\n",
    "    print(_parse_function(value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
