{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取输入数据\n",
    "## 消费 NumPy 数组\n",
    "如果所有输入数据都适合存储在内存中，则根据输入数据创建 Dataset 的最简单方法是使用`Dataset.from_tensor_slices()`\n",
    "将它们转换为 tf.Tensor 对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sess=tf.InteractiveSession()\n",
    "\n",
    "features, labels = (np.random.sample((100,2)), np.random.sample((100,1)))\n",
    "\n",
    "# Assume that each row of `features` corresponds to the same row as `labels`.\n",
    "assert features.shape[0] == labels.shape[0]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，上面的代码段会将 features 和 labels 数组作为 tf.constant() 指令嵌入在 TensorFlow 图中。这样非常适合小型数据集，但会浪费内存，因为会多次复制数组的内容，并可能会达到 tf.GraphDef 协议缓冲区的 2GB 上限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = (np.random.sample((100,2)), np.random.sample((100,1)))\n",
    "\n",
    "features_placeholder = tf.placeholder(features.dtype, features.shape)\n",
    "labels_placeholder = tf.placeholder(labels.dtype, labels.shape)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "sess.run(iterator.initializer, feed_dict={features_placeholder: features,\n",
    "                                          labels_placeholder: labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 消费TFRecord数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实就是通过tf.data.TFRecordDataset这个api来读取到TFRecord文件，生成处dataset对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(string_record):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(string_record)\n",
    "    \n",
    "    height = int(example.features.feature['height'].int64_list.value[0])\n",
    "    width = int(example.features.feature['width'].int64_list.value[0])\n",
    "    img_string = (example.features.feature['image_raw'].bytes_list.value[0])\n",
    "    label = int(example.features.feature['label'].int64_list.value[0])\n",
    "    \n",
    "    img_1d = np.frombuffer(img_string, dtype=np.uint8)\n",
    "    img = img_1d.reshape((height, width, -1))\n",
    "\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[ 59,  62,  63],\n",
      "        [ 43,  46,  45],\n",
      "        [ 50,  48,  43],\n",
      "        ...,\n",
      "        [158, 132, 108],\n",
      "        [152, 125, 102],\n",
      "        [148, 124, 103]],\n",
      "\n",
      "       [[ 16,  20,  20],\n",
      "        [  0,   0,   0],\n",
      "        [ 18,   8,   0],\n",
      "        ...,\n",
      "        [123,  88,  55],\n",
      "        [119,  83,  50],\n",
      "        [122,  87,  57]],\n",
      "\n",
      "       [[ 25,  24,  21],\n",
      "        [ 16,   7,   0],\n",
      "        [ 49,  27,   8],\n",
      "        ...,\n",
      "        [118,  84,  50],\n",
      "        [120,  84,  50],\n",
      "        [109,  73,  42]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[208, 170,  96],\n",
      "        [201, 153,  34],\n",
      "        [198, 161,  26],\n",
      "        ...,\n",
      "        [160, 133,  70],\n",
      "        [ 56,  31,   7],\n",
      "        [ 53,  34,  20]],\n",
      "\n",
      "       [[180, 139,  96],\n",
      "        [173, 123,  42],\n",
      "        [186, 144,  30],\n",
      "        ...,\n",
      "        [184, 148,  94],\n",
      "        [ 97,  62,  34],\n",
      "        [ 83,  53,  34]],\n",
      "\n",
      "       [[177, 144, 116],\n",
      "        [168, 129,  94],\n",
      "        [179, 142,  87],\n",
      "        ...,\n",
      "        [216, 184, 140],\n",
      "        [151, 118,  84],\n",
      "        [123,  92,  72]]], dtype=uint8), 6)\n"
     ]
    }
   ],
   "source": [
    "# 定义dataset 和 一些列trasformation method\n",
    "dataset = tf.data.TFRecordDataset('./99_answers/keras_cifar10_tfreocrds/cifar10_train.tfrceords')\n",
    "\n",
    "# 创建Iterator\n",
    "sample_iter = dataset.make_one_shot_iterator()\n",
    "# 获取next_sample\n",
    "next_element = sample_iter.get_next()\n",
    "\n",
    "for i in range(1):\n",
    "    value = sess.run(next_element)\n",
    "    print(_parse_function(value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
